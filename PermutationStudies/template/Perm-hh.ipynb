{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antibody levels households\n",
    "\n",
    "Check whether antibody levels in a household are more similar than one would expect statistically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import multiprocessing as mp\n",
    "from jabbar import jabbar\n",
    "from pyprojroot import here\n",
    "import os\n",
    "\n",
    "import sys\n",
    "base_path = str(here(\"\", project_files=[\".here\"]))\n",
    "perm_path = os.path.join(base_path, \"PermutationStudies\")\n",
    "if perm_path not in sys.path:\n",
    "    sys.path.insert(0, perm_path)\n",
    "from src.functions import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# control variable of interest\n",
    "var = 'hh_id'\n",
    "# measurements to study\n",
    "data_key = 'R2_Result'\n",
    "# number of permutations\n",
    "n_perm = %%n_perm%%\n",
    "\n",
    "# identifier\n",
    "id_ = f\"hh_{data_key}_{n_perm}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_blab(base_path)\n",
    "print(data.shape, \"initially\")\n",
    "\n",
    "# remove duplicate columns\n",
    "data = data.drop_duplicates(subset=['ind_id'], keep='first')\n",
    "print(data.shape, \"after remove duplicates\")\n",
    "\n",
    "# remove nans   \n",
    "data = data[data[data_key].notnull()]\n",
    "print(data.shape, \"after remove nans\")\n",
    "\n",
    "# translate results\n",
    "data[data_key] = (data[data_key] == \"Positive\").astype(float)\n",
    "\n",
    "# data plot\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.hist(data[data_key], color='C0', bins=100)\n",
    "ax.set_xlabel(data_key)\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to numpy for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_arr = get_data_arr(data, data_key)\n",
    "var_ids, var_ids_uq, var_id_matrix, var_sizes = get_var_id_stuff(data, var)\n",
    "data_matrix = create_data_matrix(data_arr, var_id_matrix)\n",
    "# control\n",
    "print(data_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(var_sizes, bins=np.arange(var_sizes.max()+1)+1, align='left')\n",
    "plt.title(\"Household size distribution\")\n",
    "plt.xlabel(\"Household size [participants]\")\n",
    "plt.ylabel(\"Number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we perform a time-intensive permutation test, we need to make the computations efficient. To check validity and efficiency, below we provide implementations in pandas, numpy, and fully vectorized numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "real_variance = statistic_var_pd(data, data_key, var, var_ids_uq)\n",
    "print(real_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy implementation with iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "real_variance = statistic_var_np_iter(data_arr, var_ids, var_ids_uq)\n",
    "print(real_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completely vectorized numpy implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_matrix_dict = create_data_matrix(data_arr, var_id_matrix)\n",
    "\n",
    "real_variance = statistic_var(data_matrix, var_sizes, var_id_matrix)\n",
    "print(real_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This >30 fold speed-up should be enough for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the methods agree on permutated data\n",
    "\n",
    "data_arr_perm = data_arr[np.random.permutation(len(data_arr))]\n",
    "\n",
    "perm_variance = statistic_var_np_iter(data_arr_perm, var_ids, var_ids_uq)\n",
    "print(perm_variance)\n",
    "\n",
    "data_matrix_perm = create_data_matrix(data_arr_perm, var_id_matrix)\n",
    "perm_variance = statistic_var(data_matrix_perm, var_sizes, var_id_matrix)\n",
    "print(perm_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# define permutations\n",
    "data_arr_perms = get_data_arr_perms(data_arr, n_perm)\n",
    "\n",
    "# for results\n",
    "variances = []\n",
    "\n",
    "# loop over all permutations\n",
    "for data_arr_perm in jabbar(data_arr_perms, symbols='ðŸ¦„'):\n",
    "    # get permutation\n",
    "    data_matrix = create_data_matrix(data_arr_perm, var_id_matrix)\n",
    "    # compute mean variance\n",
    "    variances.append(statistic_var(data_matrix, var_sizes, var_id_matrix))\n",
    "\n",
    "# to numpy arrays\n",
    "variances = np.array(variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "save_data(id_, variances=variances,\n",
    "          real_variance=real_variance,\n",
    "          perm_path=perm_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "variances, real_variance = load_data(\n",
    "    id_=id_, obj_keys=['variances', 'real_variance'],\n",
    "    perm_path=perm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for variances\n",
    "plot_kde(samples=variances, obj_key='variances', real_sample=real_variance,\n",
    "         data_key=data_key, id_=id_, suptitle=\"Average variance over households\",\n",
    "         perm_path=perm_path)\n",
    "plot_hist(samples=variances, obj_key='variances', real_sample=real_variance,\n",
    "          data_key=data_key, id_=id_, suptitle=\"Average variance over households\",\n",
    "          perm_path=perm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentiles:\")\n",
    "print(\"Variance\", data_key, sum(variances <= real_variance) / len(variances))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
